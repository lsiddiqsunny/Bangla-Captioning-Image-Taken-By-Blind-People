{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bitdeeplearningcondaeffde72656b44ccc9f803edcd0e403e5",
   "display_name": "Python 3.7.3 64-bit ('deep-learning': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import argmax\n",
    "from pickle import load\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "from numpy import array\n",
    "from pickle import load\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# load and show an image with Pillow\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "from pickle import dump\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_test = 50\n",
    "num_to_train = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# extract features from each photo in the directory\n",
    "def extract_features(annotation):\n",
    "\t# load the model\n",
    "\tmodel = VGG16()\n",
    "\t# re-structure the model\n",
    "\tmodel = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "\t# summarize\n",
    "\tprint(model.summary())\n",
    "\t# extract features from each photo\n",
    "\tfeatures = dict()\n",
    "\n",
    "\tfor i in range(num_to_test):\n",
    "\t\t# load an image from file\n",
    "\t\tfilename = ''\n",
    "\n",
    "\t\tfilename = 'Dataset/val/'+annotation['images'][i]['file_name']\n",
    "\t\timage = load_img(filename, target_size=(224, 224))\n",
    "\t\t# convert the image pixels to a numpy array\n",
    "\t\timage = img_to_array(image)\n",
    "\t\t# reshape data for the model\n",
    "\t\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "\t\t# prepare the image for the VGG model\n",
    "\t\timage = preprocess_input(image)\n",
    "\t\t# get features\n",
    "\t\tfeature = model.predict(image, verbose=0)\n",
    "\t\t# store feature\n",
    "\t\tfeatures[i] = feature\n",
    "\t\t# print('>%s' % name)\n",
    "\treturn features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def clean_descriptions(descriptions):\n",
    "\t# prepare translation table for removing punctuation\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\tfor key, desc_list in descriptions.items():\n",
    "\t\tfor i in range(len(desc_list)):\n",
    "\t\t\tdesc = desc_list[i]\n",
    "\t\t\t# tokenize\n",
    "\t\t\tdesc = desc.split()\n",
    "\t\t\t# convert to lower case\n",
    "\t\t\tdesc = [word.lower() for word in desc]\n",
    "\t\t\t# remove punctuation from each token\n",
    "\t\t\tdesc = [w.translate(table) for w in desc]\n",
    "\t\t\t# remove hanging 's' and 'a'\n",
    "\t\t\tdesc = [word for word in desc if len(word)>1]\n",
    "\t\t\t# remove tokens with numbers in them\n",
    "\t\t\tdesc = [word for word in desc if word.isalpha()]\n",
    "\t\t\t# store as string\n",
    "\t\t\tdesc_list[i] =  ' '.join(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the loaded descriptions into a vocabulary of words\n",
    "def to_vocabulary(descriptions):\n",
    "\t# build a list of all description strings\n",
    "\tall_desc = set()\n",
    "\tfor key in descriptions.keys():\n",
    "\t\t[all_desc.update(d.split()) for d in descriptions[key]]\n",
    "\treturn all_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save descriptions to file, one per line\n",
    "def save_descriptions(descriptions, filename):\n",
    "\tlines = list()\n",
    "\tfor key, desc_list in descriptions.items():\n",
    "\t\tfor desc in desc_list:\n",
    "\t\t\tlines.append(str(key) + ' ' + desc)\n",
    "\tdata = '\\n'.join(lines)\n",
    "\tfile = open(filename, 'w')\n",
    "\tfile.write(data)\n",
    "\tfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load photo features\n",
    "def load_photo_features(filename, num):\n",
    "\t# load all features\n",
    "\tall_features = load(open(filename, 'rb'))\n",
    "\t# filter features\n",
    "\tfeatures = {k: all_features[k] for k in range(num)}\n",
    "\treturn features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "# load clean descriptions into memory\n",
    "def load_clean_descriptions(filename, num):\n",
    "\t# load document\n",
    "\tdoc = load_doc(filename)\n",
    "\tdescriptions = dict()\n",
    "\tfor line in doc.split('\\n'):\n",
    "\t\t# split line by white space\n",
    "\t\ttokens = line.split()\n",
    "\t\t# split id from description\n",
    "\t\timage_id, image_desc = int(tokens[0]), tokens[1:]\n",
    "\t\t# skip images not in the set\n",
    "\t\tif image_id in range(num):\n",
    "\t\t\t# create list\n",
    "\t\t\tif image_id not in descriptions:\n",
    "\t\t\t\tdescriptions[image_id] = list()\n",
    "\t\t\t# wrap description in tokens\n",
    "\t\t\tdesc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
    "\t\t\t# store\n",
    "\t\t\tdescriptions[image_id].append(desc)\n",
    "\treturn descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a dictionary of clean descriptions to a list of descriptions\n",
    "def to_lines(descriptions):\n",
    "\tall_desc = list()\n",
    "\tfor key in descriptions.keys():\n",
    "\t\t[all_desc.append(d) for d in descriptions[key]]\n",
    "\treturn all_desc\n",
    "\n",
    "# fit a tokenizer given caption descriptions\n",
    "def create_tokenizer(descriptions):\n",
    "\tlines = to_lines(descriptions)\n",
    "\ttokenizer = Tokenizer()\n",
    "\ttokenizer.fit_on_texts(lines)\n",
    "\treturn tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the length of the description with the most words\n",
    "def max_lengths(descriptions):\n",
    "\tlines = to_lines(descriptions)\n",
    "\treturn max(len(d.split()) for d in lines)\n",
    " \n",
    "# create sequences of images, input sequences and output words for an image\n",
    "def create_sequences(tokenizer, max_length, desc_list, photo, vocab_size):\n",
    "\tX1, X2, y = list(), list(), list()\n",
    "\t#print(desc_list)\n",
    "\t# walk through each description for the image\n",
    "\tfor desc in desc_list:\n",
    "\t\t# print(desc)\n",
    "\t\t# encode the sequence\n",
    "\t\tseq = tokenizer.texts_to_sequences([desc])[0]\n",
    "\t\t# split one sequence into multiple X,y pairs\n",
    "\t\tfor i in range(1, len(seq)):\n",
    "\t\t\t# split into input and output pair\n",
    "\t\t\tin_seq, out_seq = seq[:i], seq[i]\n",
    "\t\t\t# pad input sequence\n",
    "\t\t\tin_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "\t\t\t# encode output sequence\n",
    "\t\t\tout_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "\t\t\t# store\n",
    "\t\t\tX1.append(photo)\n",
    "\t\t\tX2.append(in_seq)\n",
    "\t\t\ty.append(out_seq)\n",
    "\treturn array(X1), array(X2), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'description': 'This dataset contains crowdsourced captions of images from VizWiz datasets. This file contains the val partition.', 'license': {'url': 'https://creativecommons.org/licenses/by/4.0/', 'name': 'Attribution 4.0 International (CC BY 4.0)'}, 'url': 'https://vizwiz.org', 'version': 'VizWiz-Captions 1.0', 'year': 2019, 'contributor': 'VizWiz-Captions Consortium', 'date_created': '2019-12-23'}\n",
      "(640, 480)\n",
      "Caption # 0 :  A computer screen shows a repair prompt on the screen.\n",
      "Caption # 1 :  a computer screen with a repair automatically pop up\n",
      "Caption # 2 :  partial computer screen showing the need of repairs\n",
      "Caption # 3 :  Part of a computer monitor showing a computer repair message.\n",
      "Caption # 4 :  The top of a laptop with a blue background and dark blue text.\n",
      "(640, 480)\n",
      "Caption # 0 :  A person is holding a bottle that has medicine for the night time.\n",
      "Caption # 1 :  A bottle of medication has a white twist top.\n",
      "Caption # 2 :  night time medication bottle being held by someone\n",
      "Caption # 3 :  a person holding a small black bottle of NIGHT TIME\n",
      "Caption # 4 :  A bottle of what appears to be cough syrup held in hand.\n",
      "(640, 480)\n",
      "Caption # 0 :  a white paper showing an image of black and brown dog\n",
      "Caption # 1 :  A library book with pictures of two dogs on the cover on a wooden table.\n",
      "Caption # 2 :  A book with a black and a tan dog walking down a snowy street.\n",
      "Caption # 3 :  The book cover shows two dogs in the snow\n",
      "Caption # 4 :  A book cover title Dog Years with an image of a black and brown dog walking up the street, on the left side it has a due date sticker from a library.\n",
      "(640, 480)\n",
      "Caption # 0 :  A white box is to the left of a blue box on a wooden table.\n",
      "Caption # 1 :  A small rectangular red and white box next to a small rectangular blue box on a wooden surface.\n",
      "Caption # 2 :  two boxes of  medicine, one white and red and the other blue sitting on a table\n",
      "Caption # 3 :  Two boxes that appear to contain medication or eye drops\n",
      "Caption # 4 :  Two boxes of pharmaceutical products left in a table\n",
      "(640, 480)\n",
      "Caption # 0 :  close up of a computer monitor that is powered on.\n",
      "Caption # 1 :  A monitor has a message displayed on it.\n",
      "Caption # 2 :  Pictured here is a screenshot that shows an error message from an app.\n",
      "Caption # 3 :  Computer screen displaying an error saying the display driver is not supported by Zoom Text.\n",
      "Caption # 4 :  a screenshot of someone's monitor that is having issues\n",
      "(640, 480)\n",
      "Caption # 0 :  a DELL laptop computer screen  showing window 7 home premium\n",
      "Caption # 1 :  A computer screen with a windows dialogue box containing the login.\n",
      "Caption # 2 :  Computer screen showing a Windows 7 home premium window with a Dell logo on it.\n",
      "Caption # 3 :  A dell laptop with windows 7 home screen.\n",
      "Caption # 4 :  window screen of dell desktop or laptop showed box of windows 7\n",
      "(640, 480)\n",
      "Caption # 0 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 1 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 2 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 3 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 4 :  Quality issues are too severe to recognize visual content.\n",
      "(640, 480)\n",
      "Caption # 0 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 1 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 2 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 3 :  A close-up of a package of a computer-related item.\n",
      "Caption # 4 :  A device with Microsoft and Hewlett Packard logos, but too blurry to tell what it is\n",
      "(640, 480)\n",
      "Caption # 0 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 1 :  A bottle of lotion on the table in front of someone sitting down wearing shorts.\n",
      "Caption # 2 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 3 :  A small bottle of lotion on a table above a person's lap.\n",
      "Caption # 4 :  Quality issues are too severe to recognize visual content.\n",
      "(640, 480)\n",
      "Caption # 0 :  The interior of a bus has a horizontal bar near the ceiling for passengers to hold on to and behind it there is a sign regarding handicapped passengers.\n",
      "Caption # 1 :  A curving metal handrail with a horizontal cross piece about a foot from the bus' ceiling is directly in front of the handicap exit.\n",
      "Caption # 2 :  The overhead handrails on a bus in the city are shown with a building right outside the window below them.\n",
      "Caption # 3 :  A vehicle has a window and a gray bar.\n",
      "Caption # 4 :  A gray frame around a window that indicates seating for disabled people.\n",
      "(640, 480)\n",
      "Caption # 0 :  A view of a building with a picture of a man on it with a couple big trees in front of it.\n",
      "Caption # 1 :  SKY VIEW SNAPSHOT OF TREES IN FRONT OF A GIANT BILLBOARD.\n",
      "Caption # 2 :  view of trees and a nearby sign promoting Istikrar Sursun\n",
      "Caption # 3 :  downtown photo of several buildings, trees people and automobiles\n",
      "Caption # 4 :  White building with a brick colored roof and a sign that reads 'istikrarsursun'\n",
      "(640, 480)\n",
      "Caption # 0 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 1 :  A white object with elastic sides sitting on a wooden surface.\n",
      "Caption # 2 :  A baby diaper keep in the table shown by the image.\n",
      "Caption # 3 :  A opened up Diaper laying on a wooden surface.\n",
      "Caption # 4 :  Clean maxi Pad over a dark wooden surface.\n",
      "(640, 480)\n",
      "Caption # 0 :  appears to be a picture of prepaid card\n",
      "Caption # 1 :  Large orange and white label with a person's hand holding it.\n",
      "Caption # 2 :  Someone is holding a white envelope with an orange strip down the length of it.\n",
      "Caption # 3 :  The package contains information about the enclosed medication\n",
      "Caption # 4 :  Pictured is the top left corner of a parcel of mail.\n",
      "(640, 480)\n",
      "Caption # 0 :  A white piece of paper with a blue emblem off to the side.\n",
      "Caption # 1 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 2 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 3 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 4 :  Quality issues are too severe to recognize visual content.\n",
      "(640, 480)\n",
      "Caption # 0 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 1 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 2 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 3 :  A bright blinding light is obstructing all view\n",
      "Caption # 4 :  Quality issues are too severe to recognize visual content.\n",
      "(640, 480)\n",
      "Caption # 0 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 1 :  A set of hand held electronic children's learning devices, one for puzzles and a dictionary.\n",
      "Caption # 2 :  Two packages with children's calculators in them are on the wooden table.\n",
      "Caption # 3 :  two kids learning toys still in package laying on a table\n",
      "Caption # 4 :  Two electronic learning toys for children, both in plastic packaging.\n",
      "(640, 480)\n",
      "Caption # 0 :  A picture of what appears to be some kind of food label.\n",
      "Caption # 1 :  Obstructed view of some type of microwavable or frozen food\n",
      "Caption # 2 :  Package of frozen food on top of a white surface.\n",
      "Caption # 3 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 4 :  Some package food, looks like some kind of meat or pasta.\n",
      "(640, 480)\n",
      "Caption # 0 :  an image of a windows seven disk plate on the floor\n",
      "Caption # 1 :  A Windows 7 Ultimate Edition CD on a black counter top.\n",
      "Caption # 2 :  Windows 7 ultimate DVD and 64-bit software disc\n",
      "Caption # 3 :  Human stand beside table and CD titles windows 7\n",
      "Caption # 4 :  I see a disk for Windows 7 Ultimate.\n",
      "(640, 480)\n",
      "Caption # 0 :  A laptop screen with system dialog on the screen,\n",
      "Caption # 1 :  The corner of a black computer with type of the screen and white type on the keyboard.\n",
      "Caption # 2 :  Partial view of laptop showing upper right portion of keyboard starting with F8 key all the way to the delete key and the screen is the right hand portion showing approximately half of the screen.\n",
      "Caption # 3 :  A black laptop with the computer's specs on the screen.\n",
      "Caption # 4 :  Part of the keyboard and screen on a laptop.\n",
      "(640, 480)\n",
      "Caption # 0 :  The underside of a Dell Inspiron laptop showing the device label including the text \"Inspiron 1545\".\n",
      "Caption # 1 :  A black substance  that has letters of the commodity.\n",
      "Caption # 2 :  The back of a Dell laptop which shows the label and serial number.\n",
      "Caption # 3 :  A Dell computer number and information on the side of a computer tower.\n",
      "Caption # 4 :  Part of a laptop's specs and barcode are shown on stickers attached to the back of the laptop.\n",
      "(640, 480)\n",
      "Caption # 0 :  point of sale food or deli possibly inside of the mall or other retail outlet.\n",
      "Caption # 1 :  GLOOMY SNAPSHOT OF A SNACK BAR SITE\n",
      "Caption # 2 :  Some small mall food court restaurant is shown with two workers behind the counter and no one in line.\n",
      "Caption # 3 :  The entrance of a restaurant with a lighted sign above a counter.\n",
      "Caption # 4 :  An image of a fast food restaurant like one seen in a mall.\n",
      "(640, 480)\n",
      "Caption # 0 :  part of the white sweater whose brand is USPA\n",
      "Caption # 1 :  appears to be a picture of a shirt\n",
      "Caption # 2 :  The logo for the United States Parachute Association decorates this shirt.\n",
      "Caption # 3 :  The Logo that has been sewn onto a white shirt, a USPCA logo\n",
      "Caption # 4 :  A brown embroidered USPA logo on white fabric\n",
      "(640, 480)\n",
      "Caption # 0 :  A bright colored pillow case with a bottle and dropper on it.\n",
      "Caption # 1 :  A essential oil bottle with a dropper is on a white fabric.\n",
      "Caption # 2 :  A wonderful view of the fog windows in the room is very thick\n",
      "Caption # 3 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 4 :  An herbal dietary supplement from Walgreen's in a glass bottle with dropper.\n",
      "(640, 480)\n",
      "Caption # 0 :  Computer monitor currently on a wooden computer desk\n",
      "Caption # 1 :  A computer monitor reflects a camera flash, wires surround it.\n",
      "Caption # 2 :  A computer monitor starting up resting on a desk with a mouse and CD cases.\n",
      "Caption # 3 :  a squared computer monitor sitting on a desk with wires near it.\n",
      "Caption # 4 :  A computer monitor showing windows starting on a desk with cables around\n",
      "(640, 480)\n",
      "Caption # 0 :  A blue computer screen with white text showing stages of verifying files\n",
      "Caption # 1 :  The computer features a blue screen notifying the user that the disk needs to be checked and the status of verifying the files, and a dirty screen.\n",
      "Caption # 2 :  blue screen on computer with a bunch of white text on it\n",
      "Caption # 3 :  A sideways picture of a computer screen or TV with codes that appear to be loading something.\n",
      "Caption # 4 :  computer monitor with a windows blue error screen on it\n",
      "(640, 480)\n",
      "Caption # 0 :  Power lines stretch across an expanse of cloudy gray sky.\n",
      "Caption # 1 :  stormy clouds over a parking lot with cars, telephone poles and buildings in the background\n",
      "Caption # 2 :  View of buildings and cars on a city street on a cloudy day.\n",
      "Caption # 3 :  An outside crowded parking lot and a few buildings with an overcast sky\n",
      "Caption # 4 :  Sky is dark with clouds that look like rain can see several building and cars\n",
      "(640, 480)\n",
      "Caption # 0 :  A package of medicine, 28 tablets that are 20 milligrams.\n",
      "Caption # 1 :  A picture of a medication box sitting on a glossy stone background.\n",
      "Caption # 2 :  A box of medicine is on the dirty ground\n",
      "Caption # 3 :  a picture of a box of pills with 28 tablets on the floor\n",
      "Caption # 4 :  A box that holds 28, 20 mg tablets manufactured by the company Bristol.\n",
      "(640, 480)\n",
      "Caption # 0 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 1 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 2 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 3 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 4 :  Quality issues are too severe to recognize visual content.\n",
      "(640, 480)\n",
      "Caption # 0 :  image is blur and hard to find what it is\n",
      "Caption # 1 :  A woman in pink pajamas standing next to a white refrigerator in a kitchen.\n",
      "Caption # 2 :  The back of a woman in pink standing  at her counter and next to her white refrigerator\n",
      "Caption # 3 :  A photo of a person wearing a pink shirt and pink flower pants in a kitchen next to a refrigerator.\n",
      "Caption # 4 :  A person in red shirt and pink pajama pants stands in a kitchen near cabinets and counters.\n",
      "(640, 480)\n",
      "Caption # 0 :  A PC running Windows software is stuck at an installation prompt.\n",
      "Caption # 1 :  Part of an LCD computer screen with an error message on it is displayed in the picture.\n",
      "Caption # 2 :  A online customer service dialog that you could communicate with the vendor online.\n",
      "Caption # 3 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 4 :  Several pamphlets on top of each other as white pamphlet with black letters.\n",
      "(640, 480)\n",
      "Caption # 0 :  A view of a take out restaurant menu\n",
      "Caption # 1 :  A food menu with images of drink and food.\n",
      "Caption # 2 :  The middle part of a menu, where the black, bordered cover is located.\n",
      "Caption # 3 :  An opened restaurant menu listing all the food options\n",
      "Caption # 4 :  A portion of a menu is shown with items such as hamburger, tejano plate, shrimp plate, steak and eggs, etc.\n",
      "(640, 480)\n",
      "Caption # 0 :  A computer screen with an antenna ear behind it and a speaker on the side of it.\n",
      "Caption # 1 :  a computer monitor showing a Samsung recovery solution 4\n",
      "Caption # 2 :  Computer screen with blue background and Samsung Recovery Solution 4 message in white including a yellow triangle with ! mark and there is part of the router behind screen.\n",
      "Caption # 3 :  A computer screen is displaying a window with a message\n",
      "Caption # 4 :  A SNAPSHOT OF A COMPUTER DESKTOP SCREEN\n",
      "(640, 480)\n",
      "Caption # 0 :  A computer screen has several windows open and one says recent in red.\n",
      "Caption # 1 :  IMAGE WAS CLEAR BUT  ITS HAFE OF THE IMAGE\n",
      "Caption # 2 :  A computer screen is turned on with a dialogue box.\n",
      "Caption # 3 :  several windows open and tabs on a computer monitor\n",
      "Caption # 4 :  open browser windows on a computer screen for software.\n",
      "(640, 480)\n",
      "Caption # 0 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 1 :  UP CLOSE SNAPSHOT OF A COMPUTER SCREEN\n",
      "Caption # 2 :  A zoomed in portion of a computer screen is shown displaying some sort of Call page.\n",
      "Caption # 3 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 4 :  An image of a blue and white computer screen.\n",
      "(640, 480)\n",
      "Caption # 0 :  A TV screen displaying  a news broadcast and a shelf with an arrangement of toy.\n",
      "Caption # 1 :  A desk with a television as well as a shelf above with toys on it.\n",
      "Caption # 2 :  I see a TV that sitting on the table\n",
      "Caption # 3 :  a TV on a stand with a shelf that is cluttered above it.\n",
      "Caption # 4 :  A TV displaying the weather channel sitting under a shelf covered in random objects.\n",
      "(640, 480)\n",
      "Caption # 0 :  A person in a long sleeved green shirt is  holding a small document in his hand.\n",
      "Caption # 1 :  A person is holding onto a small piece of paper.\n",
      "Caption # 2 :  Someone wearing a camouflage shirt is holding a \n",
      "Jammin' and Crammin' ad in their left hand.\n",
      "Caption # 3 :  A person is holding a paper with an image\n",
      "Caption # 4 :  A white piece of paper with a black and white image with black text on someone's hand.\n",
      "(640, 480)\n",
      "Caption # 0 :  appears to be photo of a magazine cover featuring a winter covered street with buildings and houses around and 2 dogs traveling down the street\n",
      "Caption # 1 :  A library book about dogs sits on a brown table.\n",
      "Caption # 2 :  A library book about dogs sitting on a wooden table.\n",
      "Caption # 3 :  This library book has not been borrowed very often.\n",
      "Caption # 4 :  A book with a library sticker on the front, called \"dog years (a memoir)\" with a picture of two dogs walking down a street.\n",
      "(640, 480)\n",
      "Caption # 0 :  A package of Kirkland Signature pork chops are shown.\n",
      "Caption # 1 :  An image that shows a payment invoice for a specific establishment.\n",
      "Caption # 2 :  A label to a product with bold text on it.\n",
      "Caption # 3 :  Label for boneless center pork loin and rib chops.\n",
      "Caption # 4 :  A receipt has a part circled in red\n",
      "(640, 480)\n",
      "Caption # 0 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 1 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 2 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 3 :  A white card with black text is on the table\n",
      "Caption # 4 :  Quality issues are too severe to recognize visual content.\n",
      "(640, 480)\n",
      "Caption # 0 :  imagine how you would describe this image on the phone to a friend.\n",
      "Caption # 1 :  angled down at someone's lap and feet on the floor\n",
      "Caption # 2 :  A person's foot against a backdrop of dark cloth.\n",
      "Caption # 3 :  A person is sitting with their ankles crossed.\n",
      "Caption # 4 :  A foot is shown, as from above, with what looks like a bare arm or leg and clothing above it, partially obscuring the foot.\n",
      "(640, 480)\n",
      "Caption # 0 :  A frozen packaged dinner with a lavender and black label.\n",
      "Caption # 1 :  a package of pre made food with beef\n",
      "Caption # 2 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 3 :  Package of beef and rice dinner with white label.\n",
      "Caption # 4 :  frozen lasagna meal with a white label on the front.\n",
      "(640, 480)\n",
      "Caption # 0 :  The back of a receipt has grey text down the length.\n",
      "Caption # 1 :  An image of a person's hand holding on to both ends of a piece of paper with written text,f\n",
      "Caption # 2 :  a person holding a white piece of paper in CONDITIONS written on it\n",
      "Caption # 3 :  The back of a receipt with terms of service on a marble counter.\n",
      "Caption # 4 :  A person is holding a paper on top of a table.\n",
      "(640, 480)\n",
      "Caption # 0 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 1 :  A white sheet of paper has blurry text on it\n",
      "Caption # 2 :  A piece of paper is on the brown table but it is very blurry.\n",
      "Caption # 3 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 4 :  A close up of a sheet of paper on a wooden desk.\n",
      "(640, 480)\n",
      "Caption # 0 :  Quality issues are too severe to recognize visual content.\n",
      "Caption # 1 :  The back of a person who is wearing a white shirt\n",
      "Caption # 2 :  Someone facing away from the camera in a sitting position\n",
      "Caption # 3 :  an object that has black rectangles in it with a large square object above it\n",
      "Caption # 4 :  Quality issues are too severe to recognize visual content.\n",
      "(640, 480)\n",
      "Caption # 0 :  A Hoover vacuum cleaner filter with model number BH50010.\n",
      "Caption # 1 :  A piece of metal with a manufacturer label is resting on the carpet.\n",
      "Caption # 2 :  A grey part that goes to a vacuum cleaner sitting on top of a brown carpet.\n",
      "Caption # 3 :  A silver vacuum cleaner component with the white manufacturer label visible on a beige carpet.\n",
      "Caption # 4 :  The back part of an small electrical machine\n",
      "(640, 480)\n",
      "Caption # 0 :  A some sort of card or a ticket, it has an image of a cactus\n",
      "Caption # 1 :  a hotel key card with an image of a cactus on it\n",
      "Caption # 2 :  An image of a green cactus with the date July-08-11.\n",
      "Caption # 3 :  A white ticket is on the table with a cactus on it.\n",
      "Caption # 4 :  A label with a cactus and the word insert.\n",
      "(640, 480)\n",
      "Caption # 0 :  on a table electronic device which displays programs, news was kept, on the above shelf was full of prizes\n",
      "Caption # 1 :  The inside of a bedroom containing a TV with a video game system.\n",
      "Caption # 2 :  image contain shows a monitor running on a table.\n",
      "Caption # 3 :  A black TV sitting on a wooden counter with a image of a building\n",
      "Caption # 4 :  A television sitting on a wooden table below some shelves.\n",
      "(640, 480)\n",
      "Caption # 0 :  imagine how you would describe this image on the phone to a friend.\n",
      "Caption # 1 :  Three fingers on the right touching someone's breast with a green shirt an a blue and flower t-shirt\n",
      "Caption # 2 :  The chest of a woman wearing a floral shirt with a green corduroy shirt over top\n",
      "Caption # 3 :  A woman's chest, in a flower print top, that is being exposed by a man's hand\n",
      "Caption # 4 :  A green button down shirt covers a blue shirt with bright flowers.\n",
      "(640, 480)\n",
      "Caption # 0 :  the reflection of two people hugging in front of the original pancake house door\n",
      "Caption # 1 :  Someone in the reflection of the door for \"The Original pancake house\"\n",
      "Caption # 2 :  The sign printed on the front of a door to a pancake house.\n",
      "Caption # 3 :  Store display with white writing on the window.\n",
      "Caption # 4 :  some sort of doorway that leads to a pancake house\n",
      "(640, 480)\n",
      "Caption # 0 :  Three bottles of food product are on a table\n",
      "Caption # 1 :  A container of orange juice is shown on a table.\n",
      "Caption # 2 :  Round Glass Bottle with part writing and part lemon on.\n",
      "Caption # 3 :  THREE SMALL PLASTIC BOTTLES CONTAINING VARIOUS FOOD SUPPLEMENTS AND FOOD.\n",
      "Caption # 4 :  The side of a blue bottle of a beverage on a counter.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Extracted Features: 50\n"
     ]
    }
   ],
   "source": [
    "test_annotation = json.load(open(\"Dataset/annotations/val.json\"))\n",
    "print(test_annotation['info'])\n",
    "test_descriptions = dict()\n",
    "for i in range(num_to_test):\n",
    "    image = Image.open('Dataset/val/'+test_annotation ['images'][i]['file_name'])\n",
    "    image = image.convert(mode='L')\n",
    "    image = image.resize((640, 480))\n",
    "    print(image.size)\n",
    "    test_descriptions[i] = []\n",
    "    for j in range(5):\n",
    "        print('Caption #',j,': ',test_annotation['annotations'][i*5+j]['caption'])\n",
    "        test_descriptions[i].append(test_annotation['annotations'][i*5+j]['caption'])\n",
    "test_features = extract_features(test_annotation)\n",
    "print('Extracted Features: %d' % len(test_features))\n",
    "# save to file\n",
    "dump(test_features, open('test_features.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_descriptions(test_descriptions)\n",
    "# save descriptions\n",
    "save_descriptions(test_descriptions, 'test_descriptions.txt')\n",
    "test_descriptions = load_clean_descriptions('test_descriptions.txt', num_to_test)\n",
    "test_features = load_photo_features('test_features.pkl', num_to_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Descriptions: train=500\nVocabulary Size: 2657\nDescription Length: 52\n"
     ]
    }
   ],
   "source": [
    "# descriptions\n",
    "train_descriptions = load_clean_descriptions('descriptions.txt', num_to_train)\n",
    "print('Descriptions: train=%d' % len(train_descriptions))\n",
    "# prepare tokenizer\n",
    "tokenizer = create_tokenizer(train_descriptions)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)\n",
    "# determine the maximum sequence length\n",
    "max_length = max_lengths(train_descriptions)\n",
    "print('Description Length: %d' % max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map an integer to a word\n",
    "def word_for_id(integer, tokenizer):\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == integer:\n",
    "\t\t\treturn word\n",
    "\treturn None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a description for an image\n",
    "def generate_desc(model, tokenizer, photo, max_length):\n",
    "\t# seed the generation process\n",
    "\tin_text = 'startseq'\n",
    "\t# iterate over the whole length of the sequence\n",
    "\tfor i in range(max_length):\n",
    "\t\t# integer encode input sequence\n",
    "\t\tsequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "\t\t# pad input\n",
    "\t\tsequence = pad_sequences([sequence], maxlen=max_length)\n",
    "\t\t# predict next word\n",
    "\t\tyhat = model.predict([photo,sequence], verbose=0)\n",
    "\t\t# convert probability to integer\n",
    "\t\tyhat = argmax(yhat)\n",
    "\t\t# map integer to word\n",
    "\t\tword = word_for_id(yhat, tokenizer)\n",
    "\t\t# stop if we cannot map the word\n",
    "\t\tif word is None:\n",
    "\t\t\tbreak\n",
    "\t\t# append as input for generating the next word\n",
    "\t\tin_text += ' ' + word\n",
    "\t\t# stop if we predict the end of the sequence\n",
    "\t\tif word == 'endseq':\n",
    "\t\t\tbreak\n",
    "\treturn in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, descriptions, photos, tokenizer, max_length):\n",
    "    actual, predicted = list(), list()\n",
    "    # step over the whole set\n",
    "    for key, desc_list in descriptions.items():\n",
    "        # generate description\n",
    "        yhat = generate_desc(model, tokenizer, photos[key], max_length)\n",
    "        print(key,yhat)\n",
    "        # store actual and predicted\n",
    "        references = [d.split() for d in desc_list]\n",
    "        actual.append(references)\n",
    "        predicted.append(yhat.split())\n",
    "\t# calculate BLEU score\n",
    "    print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "    print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
    "    print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
    "    print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 startseq computer monitor is on utility monitor endseq\n",
      "1 startseq white bottle of medicine sitting on top of white table endseq\n",
      "2 startseq card with graphics on the back of the nutritional chopper endseq\n",
      "3 startseq us open red and white bill on top of it endseq\n",
      "4 startseq computer monitor you avatar mix endseq\n",
      "5 startseq computer and white menu you text text on the wall endseq\n",
      "6 startseq quality issues are too severe to recognize visual content endseq\n",
      "7 startseq quality issues are too severe to recognize visual content endseq\n",
      "8 startseq quality issues are too severe to recognize visual content endseq\n",
      "9 startseq quality issues are too severe to recognize visual content endseq\n",
      "10 startseq house with tree and tree on it endseq\n",
      "11 startseq purple shirt worn up up on bed endseq\n",
      "12 startseq an type of paper describes this instructions endseq\n",
      "13 startseq quality issues are too severe to recognize visual content endseq\n",
      "14 startseq quality issues are too severe to recognize visual content endseq\n",
      "15 startseq purple carton of clam chowder chopper by clams endseq\n",
      "16 startseq quality issues are too severe to recognize visual content endseq\n",
      "17 startseq image of white colored cars is sitting on white table endseq\n",
      "18 startseq white and white color have model have grey and grey information and have image above it endseq\n",
      "19 startseq quality issues are too severe to recognize visual content endseq\n",
      "20 startseq an open picture of fish phone on the background endseq\n",
      "21 startseq quality issues are too severe to recognize visual content endseq\n",
      "22 startseq the open label of some nasal item on wood surface endseq\n",
      "23 startseq part of computer computer phone shown and silver labels and silver and silver monitor on it endseq\n",
      "24 startseq white plaque with white information and text on the back endseq\n",
      "25 startseq quality issues are too severe to recognize visual content endseq\n",
      "26 startseq can of can of some chowder are on the table endseq\n",
      "27 startseq quality issues are too severe to recognize visual content endseq\n",
      "28 startseq quality issues are too severe to recognize visual content endseq\n",
      "29 startseq quality issues are too severe to recognize visual content endseq\n",
      "30 startseq food package of krusteaz information on white back endseq\n",
      "31 startseq white monitor is shown on white side endseq\n",
      "32 startseq quality issues are too severe to recognize visual content endseq\n",
      "33 startseq quality issues are too severe to recognize visual content endseq\n",
      "34 startseq part of computer phone sitting on white floor endseq\n",
      "35 startseq quality issues are too severe to recognize visual content endseq\n",
      "36 startseq card with graphics on the back of the brand one one on it endseq\n",
      "37 startseq directions for learning with the word inspire on it endseq\n",
      "38 startseq quality issues are too severe to recognize visual content endseq\n",
      "39 startseq electric plug take sitting on top of white floor endseq\n",
      "40 startseq food colored food on wooden table endseq\n",
      "41 startseq tube of moisturizing conditioner sitting on wood surface endseq\n",
      "42 startseq quality issues are too severe to recognize visual content endseq\n",
      "43 startseq quality issues are too severe to recognize visual content endseq\n",
      "44 startseq quality issues are too severe to recognize visual content endseq\n",
      "45 startseq quality issues are too severe to recognize visual content endseq\n",
      "46 startseq part of computer keyboard with white night night under dark mist endseq\n",
      "47 startseq red and red bag with white and black and black and the red and the red and the red and the red and the red and the red and the red and the red and the red and the red and the red and the red and the red and the red\n",
      "48 startseq quality issues are too severe to recognize visual content endseq\n",
      "49 startseq white colored juice laid on top of tan counter endseq\n",
      "BLEU-1: 0.520067\n",
      "BLEU-2: 0.370957\n",
      "BLEU-3: 0.350625\n",
      "BLEU-4: 0.284087\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "filename = 'Model\\model_19.h5'\n",
    "model = load_model(filename)\n",
    "# evaluate model\n",
    "evaluate_model(model, test_descriptions, test_features, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}